[2023-04-14 14:48:59,317] [WARNING] [runner.py:186:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-04-14 14:48:59,331] [INFO] [runner.py:550:main] cmd = /home/zhaoheng_huang/anaconda3/envs/cagsdp/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None runBert.py --model_name_or_path /home/zhaoheng_huang/CAGS_result/BERT/BERTModel --tokenizer_name /home/zhaoheng_huang/CAGS_result/BERT/BERTModel --data_path /home/zhaoheng_huang/CAGS_data/Rank/data/aol --task aol --load_plm /home/zhaoheng_huang/CAGS_result/SCL/CLModel/BertContrastive.aol --load_model /home/zhaoheng_huang/CAGS_result/Ranking/ROUTE/PointBertSessionSearch.aol --output_dir /home/zhaoheng_huang/CAGS_result/Rank --optim adamw_torch --learning_rate 5e-5 --num_train_epochs 3 --per_device_train_batch_size 2048 --per_device_eval_batch_size 2048 --evaluation_strategy steps --logging_steps 100 --log_level warning --load_best_model_at_end True --metric_for_best_model map --greater_is_better True --save_total_limit 1 --eval_steps 100 --save_steps 100 --fp16 True --deepspeed dp.json
[2023-04-14 14:49:01,008] [INFO] [launch.py:142:main] WORLD INFO DICT: {'localhost': [0, 1]}
[2023-04-14 14:49:01,008] [INFO] [launch.py:148:main] nnodes=1, num_local_procs=2, node_rank=0
[2023-04-14 14:49:01,008] [INFO] [launch.py:161:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1]})
[2023-04-14 14:49:01,008] [INFO] [launch.py:162:main] dist_world_size=2
[2023-04-14 14:49:01,008] [INFO] [launch.py:164:main] Setting CUDA_VISIBLE_DEVICES=0,1
[2023-04-14 14:49:04,331] [INFO] [comm.py:652:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Some weights of the model checkpoint at /home/zhaoheng_huang/CAGS_result/BERT/BERTModel were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at /home/zhaoheng_huang/CAGS_result/BERT/BERTModel were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Using /home/zhaoheng_huang/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
Using /home/zhaoheng_huang/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
Emitting ninja build file /home/zhaoheng_huang/.cache/torch_extensions/py38_cu117/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.45135927200317383 seconds
Loading extension module utils...
Time to load utils op: 0.40515804290771484 seconds
Rank: 1 partition count [2, 2] and sizes[(54681600, False), (61058, False)] 
Rank: 0 partition count [2, 2] and sizes[(54681600, False), (61058, False)] 
Using /home/zhaoheng_huang/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.00044655799865722656 seconds
Using /home/zhaoheng_huang/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0003364086151123047 seconds
  0%|          | 0/2079 [00:00<?, ?it/s]/home/zhaoheng_huang/anaconda3/envs/cagsdp/lib/python3.8/site-packages/transformers/data/data_collator.py:119: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)
  batch["labels"] = torch.tensor([f["label"] for f in features], dtype=dtype)
/home/zhaoheng_huang/anaconda3/envs/cagsdp/lib/python3.8/site-packages/transformers/data/data_collator.py:119: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)
  batch["labels"] = torch.tensor([f["label"] for f in features], dtype=dtype)
  0%|          | 1/2079 [00:07<4:11:08,  7.25s/it]  0%|          | 2/2079 [00:12<3:34:49,  6.21s/it]  0%|          | 3/2079 [00:18<3:22:11,  5.84s/it]  0%|          | 4/2079 [00:23<3:16:38,  5.69s/it]  0%|          | 5/2079 [00:29<3:13:18,  5.59s/it]  0%|          | 6/2079 [00:34<3:11:23,  5.54s/it]  0%|          | 7/2079 [00:39<3:10:22,  5.51s/it]  0%|          | 8/2079 [00:45<3:10:15,  5.51s/it]  0%|          | 9/2079 [00:50<3:09:58,  5.51s/it]  0%|          | 10/2079 [00:56<3:09:32,  5.50s/it]  1%|          | 11/2079 [01:01<3:09:36,  5.50s/it]  1%|          | 12/2079 [01:07<3:10:02,  5.52s/it]  1%|          | 13/2079 [01:13<3:10:37,  5.54s/it]  1%|          | 14/2079 [01:18<3:11:00,  5.55s/it]  1%|          | 15/2079 [01:24<3:11:49,  5.58s/it]  1%|          | 16/2079 [01:29<3:12:22,  5.60s/it]  1%|          | 17/2079 [01:35<3:12:42,  5.61s/it]  1%|          | 18/2079 [01:41<3:13:31,  5.63s/it]  1%|          | 19/2079 [01:46<3:13:57,  5.65s/it]  1%|          | 20/2079 [01:52<3:14:10,  5.66s/it]  1%|          | 21/2079 [01:58<3:14:11,  5.66s/it]  1%|          | 22/2079 [02:03<3:13:54,  5.66s/it]  1%|          | 23/2079 [02:09<3:12:59,  5.63s/it]  1%|          | 24/2079 [02:15<3:13:01,  5.64s/it]  1%|          | 25/2079 [02:20<3:12:48,  5.63s/it]  1%|▏         | 26/2079 [02:26<3:12:45,  5.63s/it]  1%|▏         | 27/2079 [02:32<3:12:40,  5.63s/it]  1%|▏         | 28/2079 [02:37<3:12:58,  5.65s/it]  1%|▏         | 29/2079 [02:43<3:13:19,  5.66s/it]  1%|▏         | 30/2079 [02:49<3:13:36,  5.67s/it]  1%|▏         | 31/2079 [02:54<3:13:46,  5.68s/it]  2%|▏         | 32/2079 [03:00<3:13:35,  5.67s/it]  2%|▏         | 33/2079 [03:06<3:13:33,  5.68s/it]  2%|▏         | 34/2079 [03:11<3:13:53,  5.69s/it]  2%|▏         | 35/2079 [03:17<3:13:56,  5.69s/it]  2%|▏         | 36/2079 [03:23<3:13:43,  5.69s/it]  2%|▏         | 37/2079 [03:28<3:13:30,  5.69s/it]  2%|▏         | 38/2079 [03:34<3:13:01,  5.67s/it]  2%|▏         | 39/2079 [03:40<3:12:59,  5.68s/it]  2%|▏         | 40/2079 [03:45<3:12:26,  5.66s/it]  2%|▏         | 41/2079 [03:51<3:12:22,  5.66s/it]  2%|▏         | 42/2079 [03:57<3:11:27,  5.64s/it]  2%|▏         | 43/2079 [04:02<3:11:14,  5.64s/it]  2%|▏         | 44/2079 [04:08<3:10:47,  5.63s/it]  2%|▏         | 45/2079 [04:13<3:10:29,  5.62s/it]  2%|▏         | 46/2079 [04:19<3:11:03,  5.64s/it]  2%|▏         | 47/2079 [04:25<3:11:37,  5.66s/it]  2%|▏         | 48/2079 [04:30<3:11:32,  5.66s/it]  2%|▏         | 49/2079 [04:36<3:11:10,  5.65s/it]  2%|▏         | 50/2079 [04:42<3:10:15,  5.63s/it]  2%|▏         | 51/2079 [04:47<3:09:41,  5.61s/it]  3%|▎         | 52/2079 [04:53<3:09:12,  5.60s/it]  3%|▎         | 53/2079 [04:58<3:08:54,  5.59s/it]  3%|▎         | 54/2079 [05:04<3:08:56,  5.60s/it]  3%|▎         | 55/2079 [05:10<3:07:54,  5.57s/it]  3%|▎         | 56/2079 [05:15<3:08:08,  5.58s/it]  3%|▎         | 57/2079 [05:21<3:08:03,  5.58s/it]  3%|▎         | 58/2079 [05:26<3:07:56,  5.58s/it]  3%|▎         | 59/2079 [05:32<3:08:01,  5.58s/it]  3%|▎         | 60/2079 [05:37<3:08:05,  5.59s/it]  3%|▎         | 61/2079 [05:43<3:07:46,  5.58s/it]  3%|▎         | 62/2079 [05:49<3:07:26,  5.58s/it]  3%|▎         | 63/2079 [05:54<3:07:03,  5.57s/it]  3%|▎         | 64/2079 [06:00<3:06:48,  5.56s/it]  3%|▎         | 65/2079 [06:05<3:07:10,  5.58s/it]  3%|▎         | 66/2079 [06:11<3:07:02,  5.57s/it]  3%|▎         | 67/2079 [06:16<3:06:35,  5.56s/it]